{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFJq51DWi9lB"
      },
      "source": [
        "#Multiplicação de matrizes em paralelo usando GPU com CUDA\n",
        "##Integrantes do grupo:  \n",
        "João Vitor Fidelis Cardozo, RA: 769719;  \n",
        "Rômulo Alves, RA: 757944."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A princípio, foi executado o código abaixo, o qual mostra algumas informações sobre a GPU utilizada. Nesse caso, foi a Tesla T4, a qual possui tamanho máximo de 1024 threads por bloco. É necessário ressaltar, que o tamanho do warp para esse dispositivo, é de 32 threads, então já é esperado para o trabalho, obter um ótimo desempenho caso for definido um número de threads em um bloco, como múltiplo do tamanho desse warp."
      ],
      "metadata": {
        "id": "mxxcVyb9q2J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gpu_test.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    for (int dev = 0; dev < deviceCount; dev++) {\n",
        "        cudaDeviceProp deviceProp;\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "\n",
        "        printf(\"Device %d: %s\\n\", dev, deviceProp.name);\n",
        "        printf(\"  Maximum number of threads per block: %d\\n\", deviceProp.maxThreadsPerBlock);\n",
        "        printf(\"  Maximum number of blocks per grid:   %d x %d x %d\\n\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1], deviceProp.maxGridSize[2]);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "936_Vxh1o2Iv",
        "outputId": "23729106-91bd-4c0c-aa26-fe6559382400"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gpu_test.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc gpu_test.cu -o gpu_test\n",
        "! ./gpu_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUtwNO9rpJC9",
        "outputId": "19bd16f5-df6f-48d0-f30e-bc019c3ea5a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n",
            "  Maximum number of threads per block: 1024\n",
            "  Maximum number of blocks per grid:   2147483647 x 65535 x 65535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logo abaixo, é possível verificar o código principal da multiplicação de matrizes em GPU com CUDA, verificando também, os resultados da versão serializada."
      ],
      "metadata": {
        "id": "WtU8FImwrmxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mm.cu\n",
        "\n",
        "#include <stdlib.h> \n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define DIM 32\n",
        "\n",
        "float *A, *B, *C;\n",
        "float *d_A, *d_B, *d_C;\n",
        "\n",
        "\n",
        "__global__ void multiplicacaoMatrizes(float *A, float *B, float *C, int dim) \n",
        "{\n",
        "\tunsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  unsigned idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\tint k = 0;\n",
        "\t\n",
        "\tfor (k = 0; k < dim; k++){\n",
        "\t\tif (idx < dim && idy < dim) \n",
        "\t\t\tC[idx*dim + idy] = C[idx*dim + idy] + A[idx*dim + k] * B[k*dim + idy];\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int\n",
        "main(int argc, char *argv[])\n",
        "{\n",
        "  int i,j,k;\n",
        "  int lin, col;\n",
        "\n",
        "  lin = col = DIM;\n",
        "\tsize_t tam_mat = lin * col * sizeof(float);\n",
        "\n",
        "\t// Alocacao dinâmica das matrizes, com linhas em sequência \n",
        "\tA = (float *) malloc (tam_mat);\n",
        "\tB = (float *) malloc (tam_mat);\n",
        "\tC = (float *) malloc (tam_mat);\n",
        "\n",
        " \t// Atribucao de valores iniciais às matrizes \n",
        "\t// Opa! Vai gerar valores aleatórios em paralelo?\n",
        " \tsrand(time(NULL));\n",
        "\tfor(i=0; i < lin * col; i++) { \n",
        "\t\t//A[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\t//B[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\tA[i] = 3.00;\n",
        "\t\tB[i] = 4.00;\n",
        "\t}\n",
        "\n",
        "  // zerar matriz C?\n",
        "\tfor (i=0; i < lin * col; i++){\n",
        "\t\tC[i] = 0;\n",
        "\t}\n",
        "\t\n",
        "\t//Alocação de espaço para as matrizes na GPU\n",
        "\tcudaMalloc((void **)&d_A, tam_mat);\n",
        "\tcudaMalloc((void **)&d_B, tam_mat);\n",
        "\tcudaMalloc((void **)&d_C, tam_mat);\n",
        "\n",
        "\t// Cópia dos dados de A e B para d_A e d_B. Não precisa copiar C!\n",
        "\tcudaMemcpy(d_A, A, tam_mat, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, tam_mat, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // Definição do bloco e da grade\n",
        "  dim3 block;\n",
        "  \n",
        "\t//1024 blocos;\n",
        "\n",
        "\n",
        "  block.x = 32;\n",
        "  block.y = 32;\n",
        "  block.z = 1;\n",
        "\n",
        "  dim3 grid;\n",
        "  grid.x = (DIM + block.x -1) / block.x;\n",
        "  grid.y = (DIM + block.y -1) / block.y;\n",
        "  grid.z = 1;\n",
        "\n",
        "\t// calculo da multiplicação\n",
        "\t\n",
        "\t//Invocação do kernel\n",
        "\tmultiplicacaoMatrizes <<< grid, block >>> (d_A, d_B, d_C, DIM);\n",
        "\t\n",
        "\tcudaError_t err = cudaGetLastError(); \n",
        "  if (err!= cudaSuccess) {\n",
        "    printf(\"Erro: %s\\n\", cudaGetErrorString(err));\n",
        "    exit(0);\n",
        "  }\n",
        "\n",
        "\t// Espera execução do kernel ser concluúida para transferir dados de d_C para C\n",
        "  // Também seria possível inverter, ativando cópia de memória e sincronizando depois\n",
        "\t// cudaDeviceSynchronize();\n",
        "\tcudaMemcpy(C, d_C, tam_mat, cudaMemcpyDeviceToHost);\n",
        "  cudaDeviceSynchronize();\n",
        "\t\n",
        "  // Libera memória na GPU\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "  // Conferindo os valores produzidos\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < lin * col; i++)\n",
        "    maxError = max(maxError, abs(C[i]-0.3));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "\n",
        "\tprintf(\"Resultados com CUDA:\\n\");\n",
        "\tfor (i=0; i< lin; i++){\n",
        "\t\tfor (j=0; j < col; j++){\n",
        "\t\t\tprintf(\"%f \", C[i*col+j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "\n",
        "\n",
        "\tprintf(\"\\n\\nTestando versão sequencial:\\n\");\n",
        "\t\n",
        "\t// Quais operações podem ser calculadas em paralelo?\n",
        "  // O que pode ser calculado por todas as threads ao mesmo tempo?\n",
        "   \n",
        "\tfor(i=0; i < lin; i++) \n",
        "\t\tfor(j=0; j < col; j++) {\n",
        "\t\t\t// pode ser útil usar uma variável auxiliar para os cálculos\n",
        "\t\t\tC[i*col+j]=0;\n",
        "\t\t\tfor(k=0; k < col; k++) \n",
        "\t\t\t\tC[i*col+j] = C[i*col+j] + A[i*col+k] * B[k*col+j];\n",
        "       // ser usou variável auxiliar, atribua seu valor à C[i][j]\n",
        "\t\t}\n",
        "\n",
        "\n",
        "\tprintf(\"Resultados com na versao sequencial:\\n\");\n",
        "\tfor (i=0; i< lin; i++){\n",
        "\t\tfor (j=0; j < col; j++){\n",
        "\t\t\tprintf(\"%f \", C[i*col+j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\t// Libera memória - CPU / RAM\n",
        "\tfree(A);\n",
        "\tfree(B);\n",
        "\tfree(C);\n",
        " \n",
        "\treturn(0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUFpLHk-V4HO",
        "outputId": "d5181e0e-4eaf-464c-9054-90539a7230d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc mm.cu -o mm -O3\n",
        "! ./mm\n",
        "#!nvprof --print-gpu-trace ./mm\n",
        "#! time ./mm "
      ],
      "metadata": {
        "id": "rbL-bqpBXHh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705999dc-9ea3-4fdf-e9c0-7da8679f3c70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 383.700012\n",
            "Resultados com CUDA:\n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "\n",
            "\n",
            "Testando versão sequencial:\n",
            "Resultados com na versao sequencial:\n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n",
            "384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 384.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na célula acima, é possível visualizar os resultados gerados pela versão implementada com CUDA e pela versão implementada de forma serial. É necessário ressaltar, que foi testado com uma matriz quadrada de dimensão 32, para ser possível realizar essa comparação de resultados de forma mais explícita e simplificada. \n",
        "\n",
        "Os valores atribuídos para todas as linhas da matriz A, foram 3.0 e para a matriz B, foram todos iguais a 4.0. Como resultado dessa operação (AxB), é esperado que uma matriz C seja gerada, com todas as linhas e colunas contendo o valor de 384.0. \n",
        "\n",
        "Além disso, é preciso dizer não foi utilizada uma função de gerar valores aleatórios com ponto flutuante, devido ao erro atribuído a esse tipo de operação o que, possivelmente, tornaria essa verificação de resultados incerta."
      ],
      "metadata": {
        "id": "j8v39Js-h-UZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a implementação e a verificação dos resultados obtidos, foram feitas diferentes formas de particionamento de blocos de threads, com uma matriz quadrada de dimensão 1024. É importante lembrar que o tamanho máximo do bloco, pode ser de 1024 threads. Sendo assim, essas estratégias foram:\n",
        "\n",
        "*   Tamanho de bloco de threads 8x8;\n",
        "*   Tamanho de bloco de threads 16x16;\n",
        "*   Tamanho de bloco de threads 32x32;\n",
        "*   Tamanho de bloco de threads 8x16;\n",
        "\n"
      ],
      "metadata": {
        "id": "l9zUCKHtjYaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caso 1) Testando com blocos de threads de tamanho 8x8.\n"
      ],
      "metadata": {
        "id": "axZv9IsElBpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mm_test1.cu\n",
        "\n",
        "#include <stdlib.h> \n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define DIM 1024\n",
        "\n",
        "float *A, *B, *C;\n",
        "float *d_A, *d_B, *d_C;\n",
        "\n",
        "\n",
        "__global__ void multiplicacaoMatrizes(float *A, float *B, float *C, int dim) \n",
        "{\n",
        "\tunsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  unsigned idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\tint k = 0;\n",
        "\t\n",
        "\tfor (k = 0; k < dim; k++){\n",
        "\t\tif (idx < dim && idy < dim) \n",
        "\t\t\tC[idx*dim + idy] = C[idx*dim + idy] + A[idx*dim + k] * B[k*dim + idy];\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int\n",
        "main(int argc, char *argv[])\n",
        "{\n",
        "  int i;\n",
        "  int lin, col;\n",
        "\n",
        "  lin = col = DIM;\n",
        "\tsize_t tam_mat = lin * col * sizeof(float);\n",
        "\n",
        "\t// Alocacao dinâmica das matrizes, com linhas em sequência \n",
        "\tA = (float *) malloc (tam_mat);\n",
        "\tB = (float *) malloc (tam_mat);\n",
        "\tC = (float *) malloc (tam_mat);\n",
        "\n",
        " \t// Atribucao de valores iniciais às matrizes \n",
        "\t// Opa! Vai gerar valores aleatórios em paralelo?\n",
        " \tsrand(time(NULL));\n",
        "\tfor(i=0; i < lin * col; i++) { \n",
        "\t\t//A[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\t//B[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\tA[i] = 3.00;\n",
        "\t\tB[i] = 4.00;\n",
        "\t}\n",
        "\n",
        "  // zerar matriz C?\n",
        "\tfor (i=0; i < lin * col; i++){\n",
        "\t\tC[i] = 0;\n",
        "\t}\n",
        "\t\n",
        "\t//Alocação de espaço para as matrizes na GPU\n",
        "\tcudaMalloc((void **)&d_A, tam_mat);\n",
        "\tcudaMalloc((void **)&d_B, tam_mat);\n",
        "\tcudaMalloc((void **)&d_C, tam_mat);\n",
        "\n",
        "\t// Cópia dos dados de A e B para d_A e d_B. Não precisa copiar C!\n",
        "\tcudaMemcpy(d_A, A, tam_mat, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, tam_mat, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // Definição do bloco e da grade\n",
        "  dim3 block;\n",
        "  \n",
        "\t//64 blocos - 8x8\n",
        "  block.x = 8;\n",
        "  block.y = 8;\n",
        "  block.z = 1;\n",
        "\n",
        "  dim3 grid;\n",
        "  grid.x = (DIM + block.x -1) / block.x;\n",
        "  grid.y = (DIM + block.y -1) / block.y;\n",
        "  grid.z = 1;\n",
        "\n",
        "\t// calculo da multiplicação\n",
        "\t\n",
        "\t//Invocação do kernel\n",
        "\tmultiplicacaoMatrizes <<< grid, block >>> (d_A, d_B, d_C, DIM);\n",
        "\t\n",
        "\tcudaError_t err = cudaGetLastError(); \n",
        "  if (err!= cudaSuccess) {\n",
        "    printf(\"Erro: %s\\n\", cudaGetErrorString(err));\n",
        "    exit(0);\n",
        "  }\n",
        "\n",
        "\t// Espera execução do kernel ser concluúida para transferir dados de d_C para C\n",
        "  // Também seria possível inverter, ativando cópia de memória e sincronizando depois\n",
        "\t// cudaDeviceSynchronize();\n",
        "\tcudaMemcpy(C, d_C, tam_mat, cudaMemcpyDeviceToHost);\n",
        "  cudaDeviceSynchronize();\n",
        "\t\n",
        "  // Libera memória na GPU\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "  \n",
        "  // Conferindo os valores produzidos\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < lin * col; i++)\n",
        "    maxError = max(maxError, abs(C[i]-0.3));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "   \n",
        "\n",
        "\t// Libera memória - CPU / RAM\n",
        "\tfree(A);\n",
        "\tfree(B);\n",
        "\tfree(C);\n",
        " \n",
        "\treturn(0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsmE3bEfvIlA",
        "outputId": "14403705-7593-4760-dfcd-3249bba138db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mm_test1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caso 2) Testando com blocos de threads de tamanho 16x16.\n"
      ],
      "metadata": {
        "id": "OfTFqvXrulkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mm_test2.cu\n",
        "\n",
        "#include <stdlib.h> \n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define DIM 1024\n",
        "\n",
        "float *A, *B, *C;\n",
        "float *d_A, *d_B, *d_C;\n",
        "\n",
        "\n",
        "__global__ void multiplicacaoMatrizes(float *A, float *B, float *C, int dim) \n",
        "{\n",
        "\tunsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  unsigned idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\tint k = 0;\n",
        "\t\n",
        "\tfor (k = 0; k < dim; k++){\n",
        "\t\tif (idx < dim && idy < dim) \n",
        "\t\t\tC[idx*dim + idy] = C[idx*dim + idy] + A[idx*dim + k] * B[k*dim + idy];\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int\n",
        "main(int argc, char *argv[])\n",
        "{\n",
        "  int i;\n",
        "  int lin, col;\n",
        "\n",
        "  lin = col = DIM;\n",
        "\tsize_t tam_mat = lin * col * sizeof(float);\n",
        "\n",
        "\t// Alocacao dinâmica das matrizes, com linhas em sequência \n",
        "\tA = (float *) malloc (tam_mat);\n",
        "\tB = (float *) malloc (tam_mat);\n",
        "\tC = (float *) malloc (tam_mat);\n",
        "\n",
        " \t// Atribucao de valores iniciais às matrizes \n",
        "\t// Opa! Vai gerar valores aleatórios em paralelo?\n",
        " \tsrand(time(NULL));\n",
        "\tfor(i=0; i < lin * col; i++) { \n",
        "\t\t//A[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\t//B[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\tA[i] = 3.00;\n",
        "\t\tB[i] = 4.00;\n",
        "\t}\n",
        "\n",
        "  // zerar matriz C?\n",
        "\tfor (i=0; i < lin * col; i++){\n",
        "\t\tC[i] = 0;\n",
        "\t}\n",
        "\t\n",
        "\t//Alocação de espaço para as matrizes na GPU\n",
        "\tcudaMalloc((void **)&d_A, tam_mat);\n",
        "\tcudaMalloc((void **)&d_B, tam_mat);\n",
        "\tcudaMalloc((void **)&d_C, tam_mat);\n",
        "\n",
        "\t// Cópia dos dados de A e B para d_A e d_B. Não precisa copiar C!\n",
        "\tcudaMemcpy(d_A, A, tam_mat, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, tam_mat, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // Definição do bloco e da grade\n",
        "  dim3 block;\n",
        "  \n",
        "\t//256 blocos - 16x16\n",
        "  block.x = 16;\n",
        "  block.y = 16;\n",
        "  block.z = 1;\n",
        "\n",
        "  dim3 grid;\n",
        "  grid.x = (DIM + block.x -1) / block.x;\n",
        "  grid.y = (DIM + block.y -1) / block.y;\n",
        "  grid.z = 1;\n",
        "\n",
        "\t// calculo da multiplicação\n",
        "\t\n",
        "\t//Invocação do kernel\n",
        "\tmultiplicacaoMatrizes <<< grid, block >>> (d_A, d_B, d_C, DIM);\n",
        "\t\n",
        "\tcudaError_t err = cudaGetLastError(); \n",
        "  if (err!= cudaSuccess) {\n",
        "    printf(\"Erro: %s\\n\", cudaGetErrorString(err));\n",
        "    exit(0);\n",
        "  }\n",
        "\n",
        "\t// Espera execução do kernel ser concluúida para transferir dados de d_C para C\n",
        "  // Também seria possível inverter, ativando cópia de memória e sincronizando depois\n",
        "\t// cudaDeviceSynchronize();\n",
        "\tcudaMemcpy(C, d_C, tam_mat, cudaMemcpyDeviceToHost);\n",
        "  cudaDeviceSynchronize();\n",
        "\t\n",
        "  // Libera memória na GPU\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "  \n",
        "  // Conferindo os valores produzidos\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < lin * col; i++)\n",
        "    maxError = max(maxError, abs(C[i]-0.3));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "   \n",
        "\n",
        "\t// Libera memória - CPU / RAM\n",
        "\tfree(A);\n",
        "\tfree(B);\n",
        "\tfree(C);\n",
        " \n",
        "\treturn(0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv79wEytvTV2",
        "outputId": "cdb04895-0a59-4f97-b6d3-3c25ae221246"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mm_test2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caso 3) Testando com blocos de threads de tamanho 32x32.\n"
      ],
      "metadata": {
        "id": "qqLVs6NeumnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mm_test3.cu\n",
        "\n",
        "#include <stdlib.h> \n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define DIM 1024\n",
        "\n",
        "float *A, *B, *C;\n",
        "float *d_A, *d_B, *d_C;\n",
        "\n",
        "\n",
        "__global__ void multiplicacaoMatrizes(float *A, float *B, float *C, int dim) \n",
        "{\n",
        "\tunsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  unsigned idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\tint k = 0;\n",
        "\t\n",
        "\tfor (k = 0; k < dim; k++){\n",
        "\t\tif (idx < dim && idy < dim) \n",
        "\t\t\tC[idx*dim + idy] = C[idx*dim + idy] + A[idx*dim + k] * B[k*dim + idy];\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int\n",
        "main(int argc, char *argv[])\n",
        "{\n",
        "  int i;\n",
        "  int lin, col;\n",
        "\n",
        "  lin = col = DIM;\n",
        "\tsize_t tam_mat = lin * col * sizeof(float);\n",
        "\n",
        "\t// Alocacao dinâmica das matrizes, com linhas em sequência \n",
        "\tA = (float *) malloc (tam_mat);\n",
        "\tB = (float *) malloc (tam_mat);\n",
        "\tC = (float *) malloc (tam_mat);\n",
        "\n",
        " \t// Atribucao de valores iniciais às matrizes \n",
        "\t// Opa! Vai gerar valores aleatórios em paralelo?\n",
        " \tsrand(time(NULL));\n",
        "\tfor(i=0; i < lin * col; i++) { \n",
        "\t\t//A[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\t//B[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\tA[i] = 3.00;\n",
        "\t\tB[i] = 4.00;\n",
        "\t}\n",
        "\n",
        "  // zerar matriz C?\n",
        "\tfor (i=0; i < lin * col; i++){\n",
        "\t\tC[i] = 0;\n",
        "\t}\n",
        "\t\n",
        "\t//Alocação de espaço para as matrizes na GPU\n",
        "\tcudaMalloc((void **)&d_A, tam_mat);\n",
        "\tcudaMalloc((void **)&d_B, tam_mat);\n",
        "\tcudaMalloc((void **)&d_C, tam_mat);\n",
        "\n",
        "\t// Cópia dos dados de A e B para d_A e d_B. Não precisa copiar C!\n",
        "\tcudaMemcpy(d_A, A, tam_mat, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, tam_mat, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // Definição do bloco e da grade\n",
        "  dim3 block;\n",
        "  \n",
        "\t//1024 blocos - 32x32\n",
        "  block.x = 32;\n",
        "  block.y = 32;\n",
        "  block.z = 1;\n",
        "\n",
        "  dim3 grid;\n",
        "  grid.x = (DIM + block.x -1) / block.x;\n",
        "  grid.y = (DIM + block.y -1) / block.y;\n",
        "  grid.z = 1;\n",
        "\n",
        "\t// calculo da multiplicação\n",
        "\t\n",
        "\t//Invocação do kernel\n",
        "\tmultiplicacaoMatrizes <<< grid, block >>> (d_A, d_B, d_C, DIM);\n",
        "\t\n",
        "\tcudaError_t err = cudaGetLastError(); \n",
        "  if (err!= cudaSuccess) {\n",
        "    printf(\"Erro: %s\\n\", cudaGetErrorString(err));\n",
        "    exit(0);\n",
        "  }\n",
        "\n",
        "\t// Espera execução do kernel ser concluúida para transferir dados de d_C para C\n",
        "  // Também seria possível inverter, ativando cópia de memória e sincronizando depois\n",
        "\t// cudaDeviceSynchronize();\n",
        "\tcudaMemcpy(C, d_C, tam_mat, cudaMemcpyDeviceToHost);\n",
        "  cudaDeviceSynchronize();\n",
        "\t\n",
        "  // Libera memória na GPU\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "  \n",
        "  // Conferindo os valores produzidos\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < lin * col; i++)\n",
        "    maxError = max(maxError, abs(C[i]-0.3));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "   \n",
        "\n",
        "\t// Libera memória - CPU / RAM\n",
        "\tfree(A);\n",
        "\tfree(B);\n",
        "\tfree(C);\n",
        " \n",
        "\treturn(0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwpPG-JflCHH",
        "outputId": "dc2e9f30-8365-4004-a078-29aeabc6b59f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm_test3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caso 4) Testando com blocos de threads de tamanho 8x16.\n"
      ],
      "metadata": {
        "id": "Eb61tUlQunCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mm_test4.cu\n",
        "\n",
        "#include <stdlib.h> \n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define DIM 1024\n",
        "\n",
        "float *A, *B, *C;\n",
        "float *d_A, *d_B, *d_C;\n",
        "\n",
        "\n",
        "__global__ void multiplicacaoMatrizes(float *A, float *B, float *C, int dim) \n",
        "{\n",
        "\tunsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  unsigned idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\tint k = 0;\n",
        "\t\n",
        "\tfor (k = 0; k < dim; k++){\n",
        "\t\tif (idx < dim && idy < dim) \n",
        "\t\t\tC[idx*dim + idy] = C[idx*dim + idy] + A[idx*dim + k] * B[k*dim + idy];\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int\n",
        "main(int argc, char *argv[])\n",
        "{\n",
        "  int i;\n",
        "  int lin, col;\n",
        "\n",
        "  lin = col = DIM;\n",
        "\tsize_t tam_mat = lin * col * sizeof(float);\n",
        "\n",
        "\t// Alocacao dinâmica das matrizes, com linhas em sequência \n",
        "\tA = (float *) malloc (tam_mat);\n",
        "\tB = (float *) malloc (tam_mat);\n",
        "\tC = (float *) malloc (tam_mat);\n",
        "\n",
        " \t// Atribucao de valores iniciais às matrizes \n",
        "\t// Opa! Vai gerar valores aleatórios em paralelo?\n",
        " \tsrand(time(NULL));\n",
        "\tfor(i=0; i < lin * col; i++) { \n",
        "\t\t//A[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\t//B[i]=(float)rand() / (float)RAND_MAX; \n",
        "\t\tA[i] = 3.00;\n",
        "\t\tB[i] = 4.00;\n",
        "\t}\n",
        "\n",
        "  // zerar matriz C?\n",
        "\tfor (i=0; i < lin * col; i++){\n",
        "\t\tC[i] = 0;\n",
        "\t}\n",
        "\t\n",
        "\t//Alocação de espaço para as matrizes na GPU\n",
        "\tcudaMalloc((void **)&d_A, tam_mat);\n",
        "\tcudaMalloc((void **)&d_B, tam_mat);\n",
        "\tcudaMalloc((void **)&d_C, tam_mat);\n",
        "\n",
        "\t// Cópia dos dados de A e B para d_A e d_B. Não precisa copiar C!\n",
        "\tcudaMemcpy(d_A, A, tam_mat, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, tam_mat, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // Definição do bloco e da grade\n",
        "  dim3 block;\n",
        "  \n",
        "\t//128 blocos - 8x16\n",
        "  block.x = 8;\n",
        "  block.y = 16;\n",
        "  block.z = 1;\n",
        "\n",
        "  dim3 grid;\n",
        "  grid.x = (DIM + block.x -1) / block.x;\n",
        "  grid.y = (DIM + block.y -1) / block.y;\n",
        "  grid.z = 1;\n",
        "\n",
        "\t// calculo da multiplicação\n",
        "\t\n",
        "\t//Invocação do kernel\n",
        "\tmultiplicacaoMatrizes <<< grid, block >>> (d_A, d_B, d_C, DIM);\n",
        "\t\n",
        "\tcudaError_t err = cudaGetLastError(); \n",
        "  if (err!= cudaSuccess) {\n",
        "    printf(\"Erro: %s\\n\", cudaGetErrorString(err));\n",
        "    exit(0);\n",
        "  }\n",
        "\n",
        "\t// Espera execução do kernel ser concluúida para transferir dados de d_C para C\n",
        "  // Também seria possível inverter, ativando cópia de memória e sincronizando depois\n",
        "\t// cudaDeviceSynchronize();\n",
        "\tcudaMemcpy(C, d_C, tam_mat, cudaMemcpyDeviceToHost);\n",
        "  cudaDeviceSynchronize();\n",
        "\t\n",
        "  // Libera memória na GPU\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "  \n",
        "  // Conferindo os valores produzidos\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < lin * col; i++)\n",
        "    maxError = max(maxError, abs(C[i]-0.3));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "   \n",
        "\n",
        "\t// Libera memória - CPU / RAM\n",
        "\tfree(A);\n",
        "\tfree(B);\n",
        "\tfree(C);\n",
        " \n",
        "\treturn(0);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkgN64_yvfR3",
        "outputId": "057c3aa2-9399-487e-cc85-f226f837fc46"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm_test4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparação de resultados"
      ],
      "metadata": {
        "id": "QK4DkX5YmdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc mm_test1.cu -o mm_test1\n",
        "! nvcc mm_test2.cu -o mm_test2\n",
        "! nvcc mm_test3.cu -o mm_test3\n",
        "! nvcc mm_test4.cu -o mm_test4\n"
      ],
      "metadata": {
        "id": "EMjEL__JwTWf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo Usando 8x8\n",
        "! nvprof --print-gpu-trace ./mm_test1 | grep multiplicacaoMatrizes\n",
        "! echo\n",
        "! echo Usando 16x16\n",
        "! nvprof --print-gpu-trace ./mm_test2 | grep multiplicacaoMatrizes\n",
        "! echo\n",
        "! echo Usando 32x32\n",
        "! nvprof --print-gpu-trace ./mm_test3 | grep multiplicacaoMatrizes\n",
        "! echo\n",
        "! echo Usando 8x16\n",
        "! nvprof --print-gpu-trace ./mm_test4 | grep multiplicacaoMatrizes\n",
        "! echo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAE1yMiGlf68",
        "outputId": "ede06b64-f426-4c52-bc7c-088cde232908"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando 8x8\n",
            "==20024== NVPROF is profiling process 20024, command: ./mm_test1\n",
            "==20024== Profiling application: ./mm_test1\n",
            "==20024== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "339.22ms  766.62us                    -               -         -         -         -  4.0000MB  5.0954GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "340.22ms  751.26us                    -               -         -         -         -  4.0000MB  5.1996GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "340.98ms  73.434ms          (128 128 1)         (8 8 1)        28        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  multiplicacaoMatrizes(float*, float*, float*, int) [116]\n",
            "414.42ms  691.16us                    -               -         -         -         -  4.0000MB  5.6517GB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n",
            "\n",
            "Usando 16x16\n",
            "==20043== NVPROF is profiling process 20043, command: ./mm_test2\n",
            "==20043== Profiling application: ./mm_test2\n",
            "==20043== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "380.97ms  791.07us                    -               -         -         -         -  4.0000MB  4.9380GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "382.01ms  785.53us                    -               -         -         -         -  4.0000MB  4.9728GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "382.80ms  140.46ms            (64 64 1)       (16 16 1)        28        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  multiplicacaoMatrizes(float*, float*, float*, int) [116]\n",
            "523.27ms  695.26us                    -               -         -         -         -  4.0000MB  5.6184GB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n",
            "\n",
            "Usando 32x32\n",
            "==20068== NVPROF is profiling process 20068, command: ./mm_test3\n",
            "==20068== Profiling application: ./mm_test3\n",
            "==20068== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "280.29ms  821.98us                    -               -         -         -         -  4.0000MB  4.7523GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "281.36ms  810.59us                    -               -         -         -         -  4.0000MB  4.8190GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "282.17ms  235.38ms            (32 32 1)       (32 32 1)        28        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  multiplicacaoMatrizes(float*, float*, float*, int) [116]\n",
            "517.56ms  749.56us                    -               -         -         -         -  4.0000MB  5.2114GB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n",
            "\n",
            "Usando 8x16\n",
            "==20087== NVPROF is profiling process 20087, command: ./mm_test4\n",
            "==20087== Profiling application: ./mm_test4\n",
            "==20087== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "353.22ms  762.62us                    -               -         -         -         -  4.0000MB  5.1222GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "354.22ms  753.88us                    -               -         -         -         -  4.0000MB  5.1815GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "354.98ms  73.506ms           (128 64 1)        (8 16 1)        28        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  multiplicacaoMatrizes(float*, float*, float*, int) [116]\n",
            "428.49ms  697.37us                    -               -         -         -         -  4.0000MB  5.6014GB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "tamanhoBlocos = ['8x8', '16x16', '32X32', '8X16']\n",
        "tempoObtido = [73.434, 140.46, 235.38, 73.506]\n",
        "\n",
        "plt.bar(tamanhoBlocos, tempoObtido)\n",
        "plt.ylabel('Tempo obtido em Milisegundos')\n",
        "plt.xlabel('Tamanho dos blocos')\n",
        "plt.title('Comparação gráfica de desempenho')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ccKso74wmaGH",
        "outputId": "509f9095-b98c-4638-8f52-184ee6470f3f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O melhor desempenho para a multiplicação de matrizes foi obtido quando declarado um bloco de tamanho 8x8. É necessário ressaltar, que 8x8 < 1024threads (tamanho limite) e, permite que um bloco inteiro execute em uma SM."
      ],
      "metadata": {
        "id": "fTkHDfGuyKGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qihYwkzNmawx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}